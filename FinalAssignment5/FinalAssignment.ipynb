{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalAssignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanyam8055/EIP-4.0-/blob/master/FinalAssignment5/FinalAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6fgLrlQq_xN",
        "colab_type": "code",
        "outputId": "82d9c17c-034f-4283-8eb7-95d5c09bd0e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip -q \"/content/drive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls\n",
        "%tensorflow_version 1.x\n",
        "!pip install bokeh\n",
        "import cv2\n",
        "import json\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "from keras.applications import VGG16,InceptionV3, ResNet50V2\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam,SGD,RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()\n",
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True, augmentation=True):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.augmentation = augmentation\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15, random_state=1)\n",
        "train_df.shape, val_df.shape\n",
        "train_df.head()\n",
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=128)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=128, shuffle=True)\n",
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "replace resized/9733.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace resized/63.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh) (19.2)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (1.17.4)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh) (3.13)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh) (4.3.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from bokeh) (1.12.0)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh) (4.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.6.1)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.10.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=16.8->bokeh) (2.4.5)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.0->bokeh) (0.46)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh) (1.1.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_81EkyJIMnRk",
        "colab_type": "code",
        "outputId": "07dd2c43-1e1e-41e3-fd59-15f98ccc40c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "backbone = ResNet50V2(\n",
        "    weights=None, \n",
        "    include_top=True, \n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        ")\n",
        "\n",
        "neck = backbone.output\n",
        "\n",
        "\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    neck = Dropout(0.3)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_tower(neck))\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")\n",
        "\n",
        "from keras.callbacks import *\n",
        "\n",
        "\n",
        "\n",
        "# model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=10)\n",
        "model.summary()\n",
        " # checkpoint\n",
        "filepath=\"/content/drive/My Drive/Colab Notebooks/weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath,monitor='val_loss', verbose=1,save_weights_only=False, save_best_only=True)  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d_13[0][0]           \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_14[0][0]           \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_15[0][0]           \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "probs (Dense)                   (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 1000)         0           probs[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 1000)         0           probs[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 1000)         0           probs[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 1000)         0           probs[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 1000)         0           probs[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 1000)         0           probs[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 1000)         0           probs[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 1000)         0           probs[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_52 (Dense)                (None, 128)          128128      dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_54 (Dense)                (None, 128)          128128      dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_56 (Dense)                (None, 128)          128128      dropout_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_58 (Dense)                (None, 128)          128128      dropout_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_60 (Dense)                (None, 128)          128128      dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_62 (Dense)                (None, 128)          128128      dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_66 (Dense)                (None, 128)          128128      dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_64 (Dense)                (None, 128)          128128      dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            258         dense_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "image_quality_output (Dense)    (None, 3)            387         dense_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "age_output (Dense)              (None, 5)            645         dense_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "weight_output (Dense)           (None, 4)            516         dense_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bag_output (Dense)              (None, 3)            387         dense_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "footwear_output (Dense)         (None, 3)            387         dense_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pose_output (Dense)             (None, 3)            387         dense_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "emotion_output (Dense)          (None, 4)            516         dense_64[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 26,642,307\n",
            "Trainable params: 26,596,867\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3eRTqbDSs9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_lr(model, start_lr, end_lr):\n",
        "    finder = LRFinder(start_lr, end_lr, len(train_gen))\n",
        "    weights = model.get_weights()    \n",
        "    try:\n",
        "        history = model.fit_generator(\n",
        "            generator=train_gen,\n",
        "            validation_data=valid_gen,\n",
        "            epochs=1,\n",
        "            verbose=1,\n",
        "            callbacks=[finder],\n",
        "        )   \n",
        "    finally:    \n",
        "        model.set_weights(weights)    \n",
        "    return finder\n",
        "    \n",
        "class LRFinder(Callback):    \n",
        "    def __init__(self, start_lr=1e-5, end_lr=10, step_size=None, beta=.98):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.start_lr = start_lr\n",
        "        self.end_lr = end_lr\n",
        "        self.step_size = step_size\n",
        "        self.beta = beta\n",
        "        self.lr_mult = (end_lr/start_lr)**(1/step_size)\n",
        "        \n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.best_loss = 1e9\n",
        "        self.avg_loss = 0\n",
        "        self.losses, self.smoothed_losses, self.lrs, self.iterations = [], [], [], []\n",
        "        self.iteration = 0\n",
        "        logs = logs or {}\n",
        "        K.set_value(self.model.optimizer.lr, self.start_lr)\n",
        "        \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        loss = logs.get('loss')\n",
        "        self.iteration += 1\n",
        "        \n",
        "        self.avg_loss = self.beta * self.avg_loss + (1 - self.beta) * loss\n",
        "        smoothed_loss = self.avg_loss / (1 - self.beta**self.iteration)\n",
        "        \n",
        "        # Check if the loss is not exploding\n",
        "        if self.iteration>1 and smoothed_loss > self.best_loss * 4:\n",
        "            self.model.stop_training = True\n",
        "            return\n",
        "\n",
        "        if smoothed_loss < self.best_loss or self.iteration==1:\n",
        "            self.best_loss = smoothed_loss\n",
        "        \n",
        "        lr = self.start_lr * (self.lr_mult**self.iteration)\n",
        "        \n",
        "        self.losses.append(loss)\n",
        "        self.smoothed_losses.append(smoothed_loss)\n",
        "        self.lrs.append(lr)\n",
        "        self.iterations.append(self.iteration)        \n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, lr)  \n",
        "\n",
        "    def plot(self, lskip=10, rskip=10):\n",
        "        lrs = self.lrs[lskip:-rskip]\n",
        "        losses = self.smoothed_losses[lskip:-rskip]\n",
        "\n",
        "        output_notebook()\n",
        "        p = figure(title='Learning Rate Finder', x_axis_label='LR', y_axis_label='Loss')\n",
        "        p.line(lrs, losses)\n",
        "        show(p)\n",
        "        \n",
        "        best_idxs = np.argpartition(losses, 15)[:15]\n",
        "        best_lrs = np.take(lrs, best_idxs)\n",
        "        print(f\"Best LRs: {best_lrs}\")    \n",
        "#Cyclic Learning Rate\n",
        "class CyclicLR(Callback):\n",
        "  \n",
        "\n",
        "    def __init__(self, base_lr=0.00000005, max_lr=0.009, step_size=2000., mode='triangular',\n",
        "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDZhNTWnjAaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = RMSprop()\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "#finder = find_lr(model, 1e-7, 1e-3)\n",
        "#finder.plot()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qeXeAS4U0FM",
        "colab_type": "code",
        "outputId": "5b7ad468-381d-4f13-9b5d-23be4379a52e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\t# add image augmentation\n",
        "train_gen = PersonDataGenerator(\n",
        "    train_df, \n",
        "    augmentation=ImageDataGenerator(\n",
        "        zca_whitening=True,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "    )\n",
        ")\n",
        "clr_triangular = CyclicLR(1e-5,6e-3,mode='triangular')\n",
        "history=model.fit_generator(  \n",
        "    steps_per_epoch=20000 // 64,  validation_steps=2000 // 128,\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=8, \n",
        "    epochs=25,\n",
        "    verbose=1,callbacks=[checkpoint,clr_triangular]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:336: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "  2/312 [..............................] - ETA: 35:14 - loss: 9.4664 - gender_output_loss: 0.6932 - image_quality_output_loss: 1.0994 - age_output_loss: 1.6091 - weight_output_loss: 1.3859 - bag_output_loss: 1.0987 - footwear_output_loss: 1.0977 - pose_output_loss: 1.0976 - emotion_output_loss: 1.3848 - gender_output_acc: 0.4062 - image_quality_output_acc: 0.1406 - age_output_acc: 0.3281 - weight_output_acc: 0.2812 - bag_output_acc: 0.2500 - footwear_output_acc: 0.5156 - pose_output_acc: 0.6094 - emotion_output_acc: 0.7031  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.484488). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "312/312 [==============================] - 173s 556ms/step - loss: 8.4368 - gender_output_loss: 0.6860 - image_quality_output_loss: 1.0190 - age_output_loss: 1.5011 - weight_output_loss: 1.1359 - bag_output_loss: 0.9800 - footwear_output_loss: 1.0562 - pose_output_loss: 0.9818 - emotion_output_loss: 1.0767 - gender_output_acc: 0.5673 - image_quality_output_acc: 0.5452 - age_output_acc: 0.4065 - weight_output_acc: 0.6185 - bag_output_acc: 0.5538 - footwear_output_acc: 0.4462 - pose_output_acc: 0.6187 - emotion_output_acc: 0.7159 - val_loss: 8.0088 - val_gender_output_loss: 0.6849 - val_image_quality_output_loss: 0.9928 - val_age_output_loss: 1.4529 - val_weight_output_loss: 0.9850 - val_bag_output_loss: 0.9444 - val_footwear_output_loss: 1.0468 - val_pose_output_loss: 0.9233 - val_emotion_output_loss: 0.9787 - val_gender_output_acc: 0.5641 - val_image_quality_output_acc: 0.5536 - val_age_output_acc: 0.3667 - val_weight_output_acc: 0.6443 - val_bag_output_acc: 0.5464 - val_footwear_output_acc: 0.3719 - val_pose_output_acc: 0.6188 - val_emotion_output_acc: 0.6807\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 8.00876, saving model to /content/drive/My Drive/Colab Notebooks/weights.01-8.01.hdf5\n",
            "Epoch 2/25\n",
            "312/312 [==============================] - 158s 507ms/step - loss: 7.8436 - gender_output_loss: 0.6874 - image_quality_output_loss: 0.9857 - age_output_loss: 1.4247 - weight_output_loss: 0.9786 - bag_output_loss: 0.9097 - footwear_output_loss: 1.0265 - pose_output_loss: 0.9332 - emotion_output_loss: 0.8977 - gender_output_acc: 0.5584 - image_quality_output_acc: 0.5490 - age_output_acc: 0.4044 - weight_output_acc: 0.6374 - bag_output_acc: 0.5688 - footwear_output_acc: 0.4753 - pose_output_acc: 0.6152 - emotion_output_acc: 0.7181 - val_loss: 8.0015 - val_gender_output_loss: 0.6860 - val_image_quality_output_loss: 0.9849 - val_age_output_loss: 1.4436 - val_weight_output_loss: 0.9889 - val_bag_output_loss: 0.9425 - val_footwear_output_loss: 1.0653 - val_pose_output_loss: 0.9318 - val_emotion_output_loss: 0.9584 - val_gender_output_acc: 0.5604 - val_image_quality_output_acc: 0.5547 - val_age_output_acc: 0.3682 - val_weight_output_acc: 0.6380 - val_bag_output_acc: 0.5432 - val_footwear_output_acc: 0.3693 - val_pose_output_acc: 0.6109 - val_emotion_output_acc: 0.6875\n",
            "\n",
            "Epoch 00002: val_loss improved from 8.00876 to 8.00146, saving model to /content/drive/My Drive/Colab Notebooks/weights.02-8.00.hdf5\n",
            "Epoch 3/25\n",
            "312/312 [==============================] - 158s 507ms/step - loss: 7.8437 - gender_output_loss: 0.6866 - image_quality_output_loss: 0.9861 - age_output_loss: 1.4350 - weight_output_loss: 0.9882 - bag_output_loss: 0.9163 - footwear_output_loss: 0.9985 - pose_output_loss: 0.9323 - emotion_output_loss: 0.9007 - gender_output_acc: 0.5635 - image_quality_output_acc: 0.5523 - age_output_acc: 0.3985 - weight_output_acc: 0.6344 - bag_output_acc: 0.5691 - footwear_output_acc: 0.5198 - pose_output_acc: 0.6165 - emotion_output_acc: 0.7165 - val_loss: 8.5366 - val_gender_output_loss: 0.6860 - val_image_quality_output_loss: 0.9869 - val_age_output_loss: 1.4561 - val_weight_output_loss: 1.0056 - val_bag_output_loss: 0.9272 - val_footwear_output_loss: 1.5801 - val_pose_output_loss: 0.9316 - val_emotion_output_loss: 0.9631 - val_gender_output_acc: 0.5672 - val_image_quality_output_acc: 0.5557 - val_age_output_acc: 0.3641 - val_weight_output_acc: 0.6391 - val_bag_output_acc: 0.5547 - val_footwear_output_acc: 0.3672 - val_pose_output_acc: 0.6125 - val_emotion_output_acc: 0.6870\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 8.00146\n",
            "Epoch 4/25\n",
            "312/312 [==============================] - 159s 511ms/step - loss: 7.8432 - gender_output_loss: 0.6871 - image_quality_output_loss: 0.9803 - age_output_loss: 1.4252 - weight_output_loss: 0.9977 - bag_output_loss: 0.9193 - footwear_output_loss: 1.0022 - pose_output_loss: 0.9222 - emotion_output_loss: 0.9091 - gender_output_acc: 0.5566 - image_quality_output_acc: 0.5574 - age_output_acc: 0.4068 - weight_output_acc: 0.6314 - bag_output_acc: 0.5617 - footwear_output_acc: 0.5188 - pose_output_acc: 0.6241 - emotion_output_acc: 0.7131 - val_loss: 7.9505 - val_gender_output_loss: 0.6861 - val_image_quality_output_loss: 0.9872 - val_age_output_loss: 1.4446 - val_weight_output_loss: 0.9796 - val_bag_output_loss: 0.9355 - val_footwear_output_loss: 1.0050 - val_pose_output_loss: 0.9296 - val_emotion_output_loss: 0.9829 - val_gender_output_acc: 0.5594 - val_image_quality_output_acc: 0.5495 - val_age_output_acc: 0.3724 - val_weight_output_acc: 0.6443 - val_bag_output_acc: 0.5469 - val_footwear_output_acc: 0.5224 - val_pose_output_acc: 0.6156 - val_emotion_output_acc: 0.6875\n",
            "\n",
            "Epoch 00004: val_loss improved from 8.00146 to 7.95048, saving model to /content/drive/My Drive/Colab Notebooks/weights.04-7.95.hdf5\n",
            "Epoch 5/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.8300 - gender_output_loss: 0.6816 - image_quality_output_loss: 0.9820 - age_output_loss: 1.4267 - weight_output_loss: 0.9834 - bag_output_loss: 0.9211 - footwear_output_loss: 0.9986 - pose_output_loss: 0.9349 - emotion_output_loss: 0.9015 - gender_output_acc: 0.5670 - image_quality_output_acc: 0.5547 - age_output_acc: 0.4002 - weight_output_acc: 0.6330 - bag_output_acc: 0.5631 - footwear_output_acc: 0.5194 - pose_output_acc: 0.6144 - emotion_output_acc: 0.7160\n",
            "Epoch 00004: val_loss improved from 8.00146 to 7.95048, saving model to /content/drive/My Drive/Colab Notebooks/weights.04-7.95.hdf5\n",
            "312/312 [==============================] - 159s 508ms/step - loss: 7.8301 - gender_output_loss: 0.6816 - image_quality_output_loss: 0.9820 - age_output_loss: 1.4266 - weight_output_loss: 0.9831 - bag_output_loss: 0.9213 - footwear_output_loss: 0.9990 - pose_output_loss: 0.9352 - emotion_output_loss: 0.9013 - gender_output_acc: 0.5668 - image_quality_output_acc: 0.5549 - age_output_acc: 0.4002 - weight_output_acc: 0.6333 - bag_output_acc: 0.5624 - footwear_output_acc: 0.5192 - pose_output_acc: 0.6142 - emotion_output_acc: 0.7160 - val_loss: 8.0195 - val_gender_output_loss: 0.6887 - val_image_quality_output_loss: 0.9855 - val_age_output_loss: 1.4504 - val_weight_output_loss: 0.9739 - val_bag_output_loss: 0.9430 - val_footwear_output_loss: 1.0611 - val_pose_output_loss: 0.9289 - val_emotion_output_loss: 0.9879 - val_gender_output_acc: 0.5823 - val_image_quality_output_acc: 0.5521 - val_age_output_acc: 0.3708 - val_weight_output_acc: 0.6432 - val_bag_output_acc: 0.5479 - val_footwear_output_acc: 0.4651 - val_pose_output_acc: 0.6141 - val_emotion_output_acc: 0.6844\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 7.95048\n",
            "Epoch 6/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.7770 - gender_output_loss: 0.6731 - image_quality_output_loss: 0.9867 - age_output_loss: 1.4201 - weight_output_loss: 0.9830 - bag_output_loss: 0.9088 - footwear_output_loss: 0.9792 - pose_output_loss: 0.9288 - emotion_output_loss: 0.8972 - gender_output_acc: 0.5817 - image_quality_output_acc: 0.5476 - age_output_acc: 0.4067 - weight_output_acc: 0.6360 - bag_output_acc: 0.5696 - footwear_output_acc: 0.5367 - pose_output_acc: 0.6196 - emotion_output_acc: 0.7191\n",
            "Epoch 00005: val_loss did not improve from 7.95048\n",
            "Epoch 6/25\n",
            "312/312 [==============================] - 159s 510ms/step - loss: 7.7759 - gender_output_loss: 0.6731 - image_quality_output_loss: 0.9864 - age_output_loss: 1.4193 - weight_output_loss: 0.9829 - bag_output_loss: 0.9093 - footwear_output_loss: 0.9786 - pose_output_loss: 0.9286 - emotion_output_loss: 0.8976 - gender_output_acc: 0.5818 - image_quality_output_acc: 0.5480 - age_output_acc: 0.4077 - weight_output_acc: 0.6360 - bag_output_acc: 0.5691 - footwear_output_acc: 0.5372 - pose_output_acc: 0.6198 - emotion_output_acc: 0.7190 - val_loss: 7.9217 - val_gender_output_loss: 0.6614 - val_image_quality_output_loss: 0.9791 - val_age_output_loss: 1.4549 - val_weight_output_loss: 0.9903 - val_bag_output_loss: 0.9301 - val_footwear_output_loss: 0.9979 - val_pose_output_loss: 0.9432 - val_emotion_output_loss: 0.9647 - val_gender_output_acc: 0.6141 - val_image_quality_output_acc: 0.5589 - val_age_output_acc: 0.3688 - val_weight_output_acc: 0.6396 - val_bag_output_acc: 0.5458 - val_footwear_output_acc: 0.5198 - val_pose_output_acc: 0.6135 - val_emotion_output_acc: 0.6854\n",
            "\n",
            "Epoch 00006: val_loss improved from 7.95048 to 7.92167, saving model to /content/drive/My Drive/Colab Notebooks/weights.06-7.92.hdf5\n",
            "Epoch 7/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.6831 - gender_output_loss: 0.6517 - image_quality_output_loss: 0.9815 - age_output_loss: 1.4077 - weight_output_loss: 0.9837 - bag_output_loss: 0.9056 - footwear_output_loss: 0.9220 - pose_output_loss: 0.9239 - emotion_output_loss: 0.9070 - gender_output_acc: 0.6098 - image_quality_output_acc: 0.5566 - age_output_acc: 0.4056 - weight_output_acc: 0.6360 - bag_output_acc: 0.5630 - footwear_output_acc: 0.5815 - pose_output_acc: 0.6194 - emotion_output_acc: 0.7136\n",
            "Epoch 00006: val_loss improved from 7.95048 to 7.92167, saving model to /content/drive/My Drive/Colab Notebooks/weights.06-7.92.hdf5\n",
            "312/312 [==============================] - 159s 509ms/step - loss: 7.6818 - gender_output_loss: 0.6519 - image_quality_output_loss: 0.9810 - age_output_loss: 1.4073 - weight_output_loss: 0.9834 - bag_output_loss: 0.9054 - footwear_output_loss: 0.9216 - pose_output_loss: 0.9238 - emotion_output_loss: 0.9074 - gender_output_acc: 0.6094 - image_quality_output_acc: 0.5572 - age_output_acc: 0.4058 - weight_output_acc: 0.6361 - bag_output_acc: 0.5635 - footwear_output_acc: 0.5819 - pose_output_acc: 0.6194 - emotion_output_acc: 0.7134 - val_loss: 8.3084 - val_gender_output_loss: 0.6905 - val_image_quality_output_loss: 0.9873 - val_age_output_loss: 1.4381 - val_weight_output_loss: 0.9819 - val_bag_output_loss: 0.9297 - val_footwear_output_loss: 1.3691 - val_pose_output_loss: 0.9431 - val_emotion_output_loss: 0.9687 - val_gender_output_acc: 0.5667 - val_image_quality_output_acc: 0.5542 - val_age_output_acc: 0.3693 - val_weight_output_acc: 0.6406 - val_bag_output_acc: 0.5417 - val_footwear_output_acc: 0.4698 - val_pose_output_acc: 0.6099 - val_emotion_output_acc: 0.6839\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 7.92167\n",
            "Epoch 8/25\n",
            "312/312 [==============================] - 159s 510ms/step - loss: 7.5736 - gender_output_loss: 0.6274 - image_quality_output_loss: 0.9801 - age_output_loss: 1.4079 - weight_output_loss: 0.9789 - bag_output_loss: 0.8931 - footwear_output_loss: 0.8746 - pose_output_loss: 0.9164 - emotion_output_loss: 0.8951 - gender_output_acc: 0.6435 - image_quality_output_acc: 0.5502 - age_output_acc: 0.4023 - weight_output_acc: 0.6350 - bag_output_acc: 0.5715 - footwear_output_acc: 0.6141 - pose_output_acc: 0.6168 - emotion_output_acc: 0.7171 - val_loss: 7.9320 - val_gender_output_loss: 0.6259 - val_image_quality_output_loss: 0.9829 - val_age_output_loss: 1.4255 - val_weight_output_loss: 0.9803 - val_bag_output_loss: 0.9202 - val_footwear_output_loss: 1.0755 - val_pose_output_loss: 0.9448 - val_emotion_output_loss: 0.9770 - val_gender_output_acc: 0.6552 - val_image_quality_output_acc: 0.5536 - val_age_output_acc: 0.3708 - val_weight_output_acc: 0.6438 - val_bag_output_acc: 0.5349 - val_footwear_output_acc: 0.5068 - val_pose_output_acc: 0.6177 - val_emotion_output_acc: 0.6849\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 7.92167\n",
            "Epoch 9/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.4855 - gender_output_loss: 0.6062 - image_quality_output_loss: 0.9754 - age_output_loss: 1.4003 - weight_output_loss: 0.9755 - bag_output_loss: 0.8828 - footwear_output_loss: 0.8440 - pose_output_loss: 0.9080 - emotion_output_loss: 0.8933 - gender_output_acc: 0.6733 - image_quality_output_acc: 0.5535 - age_output_acc: 0.4027 - weight_output_acc: 0.6309 - bag_output_acc: 0.5816 - footwear_output_acc: 0.6309 - pose_output_acc: 0.6178 - emotion_output_acc: 0.7157\n",
            "Epoch 00008: val_loss did not improve from 7.92167\n",
            "Epoch 9/25\n",
            "312/312 [==============================] - 160s 512ms/step - loss: 7.4849 - gender_output_loss: 0.6062 - image_quality_output_loss: 0.9754 - age_output_loss: 1.4005 - weight_output_loss: 0.9760 - bag_output_loss: 0.8826 - footwear_output_loss: 0.8437 - pose_output_loss: 0.9080 - emotion_output_loss: 0.8926 - gender_output_acc: 0.6737 - image_quality_output_acc: 0.5536 - age_output_acc: 0.4024 - weight_output_acc: 0.6303 - bag_output_acc: 0.5813 - footwear_output_acc: 0.6313 - pose_output_acc: 0.6180 - emotion_output_acc: 0.7160 - val_loss: 7.6259 - val_gender_output_loss: 0.5907 - val_image_quality_output_loss: 0.9729 - val_age_output_loss: 1.4169 - val_weight_output_loss: 0.9723 - val_bag_output_loss: 0.9135 - val_footwear_output_loss: 0.8998 - val_pose_output_loss: 0.9087 - val_emotion_output_loss: 0.9510 - val_gender_output_acc: 0.6771 - val_image_quality_output_acc: 0.5557 - val_age_output_acc: 0.3776 - val_weight_output_acc: 0.6396 - val_bag_output_acc: 0.5411 - val_footwear_output_acc: 0.6036 - val_pose_output_acc: 0.6115 - val_emotion_output_acc: 0.6885\n",
            "\n",
            "Epoch 00009: val_loss improved from 7.92167 to 7.62586, saving model to /content/drive/My Drive/Colab Notebooks/weights.09-7.63.hdf5\n",
            "Epoch 10/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.4222 - gender_output_loss: 0.5768 - image_quality_output_loss: 0.9706 - age_output_loss: 1.3969 - weight_output_loss: 0.9672 - bag_output_loss: 0.8804 - footwear_output_loss: 0.8372 - pose_output_loss: 0.9017 - emotion_output_loss: 0.8914 - gender_output_acc: 0.6946 - image_quality_output_acc: 0.5556 - age_output_acc: 0.4010 - weight_output_acc: 0.6383 - bag_output_acc: 0.5851 - footwear_output_acc: 0.6326 - pose_output_acc: 0.6192 - emotion_output_acc: 0.7164\n",
            "Epoch 00009: val_loss improved from 7.92167 to 7.62586, saving model to /content/drive/My Drive/Colab Notebooks/weights.09-7.63.hdf5\n",
            "312/312 [==============================] - 159s 510ms/step - loss: 7.4225 - gender_output_loss: 0.5772 - image_quality_output_loss: 0.9707 - age_output_loss: 1.3967 - weight_output_loss: 0.9667 - bag_output_loss: 0.8809 - footwear_output_loss: 0.8373 - pose_output_loss: 0.9018 - emotion_output_loss: 0.8913 - gender_output_acc: 0.6944 - image_quality_output_acc: 0.5552 - age_output_acc: 0.4012 - weight_output_acc: 0.6385 - bag_output_acc: 0.5846 - footwear_output_acc: 0.6325 - pose_output_acc: 0.6192 - emotion_output_acc: 0.7164 - val_loss: 7.6236 - val_gender_output_loss: 0.6125 - val_image_quality_output_loss: 0.9784 - val_age_output_loss: 1.4249 - val_weight_output_loss: 0.9633 - val_bag_output_loss: 0.9160 - val_footwear_output_loss: 0.8587 - val_pose_output_loss: 0.8994 - val_emotion_output_loss: 0.9705 - val_gender_output_acc: 0.6682 - val_image_quality_output_acc: 0.5365 - val_age_output_acc: 0.3682 - val_weight_output_acc: 0.6438 - val_bag_output_acc: 0.5411 - val_footwear_output_acc: 0.6172 - val_pose_output_acc: 0.6156 - val_emotion_output_acc: 0.6839\n",
            "\n",
            "Epoch 00010: val_loss improved from 7.62586 to 7.62361, saving model to /content/drive/My Drive/Colab Notebooks/weights.10-7.62.hdf5\n",
            "Epoch 11/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.3530 - gender_output_loss: 0.5616 - image_quality_output_loss: 0.9785 - age_output_loss: 1.3896 - weight_output_loss: 0.9727 - bag_output_loss: 0.8633 - footwear_output_loss: 0.8013 - pose_output_loss: 0.8911 - emotion_output_loss: 0.8949 - gender_output_acc: 0.7074 - image_quality_output_acc: 0.5512 - age_output_acc: 0.4067 - weight_output_acc: 0.6316 - bag_output_acc: 0.5988 - footwear_output_acc: 0.6490 - pose_output_acc: 0.6150 - emotion_output_acc: 0.7136\n",
            "312/312 [==============================] - 158s 508ms/step - loss: 7.3540 - gender_output_loss: 0.5625 - image_quality_output_loss: 0.9788 - age_output_loss: 1.3899 - weight_output_loss: 0.9724 - bag_output_loss: 0.8635 - footwear_output_loss: 0.8011 - pose_output_loss: 0.8909 - emotion_output_loss: 0.8948 - gender_output_acc: 0.7070 - image_quality_output_acc: 0.5511 - age_output_acc: 0.4067 - weight_output_acc: 0.6318 - bag_output_acc: 0.5986 - footwear_output_acc: 0.6491 - pose_output_acc: 0.6152 - emotion_output_acc: 0.7136 - val_loss: 7.5632 - val_gender_output_loss: 0.5851 - val_image_quality_output_loss: 0.9734 - val_age_output_loss: 1.4315 - val_weight_output_loss: 0.9720 - val_bag_output_loss: 0.9014 - val_footwear_output_loss: 0.8737 - val_pose_output_loss: 0.8710 - val_emotion_output_loss: 0.9551 - val_gender_output_acc: 0.7005 - val_image_quality_output_acc: 0.5563 - val_age_output_acc: 0.3672 - val_weight_output_acc: 0.6396 - val_bag_output_acc: 0.5818 - val_footwear_output_acc: 0.6177 - val_pose_output_acc: 0.6172 - val_emotion_output_acc: 0.6849\n",
            "\n",
            "Epoch 00011: val_loss improved from 7.62361 to 7.56320, saving model to /content/drive/My Drive/Colab Notebooks/weights.11-7.56.hdf5\n",
            "Epoch 12/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.2851 - gender_output_loss: 0.5356 - image_quality_output_loss: 0.9702 - age_output_loss: 1.3898 - weight_output_loss: 0.9614 - bag_output_loss: 0.8629 - footwear_output_loss: 0.8110 - pose_output_loss: 0.8688 - emotion_output_loss: 0.8853 - gender_output_acc: 0.7262 - image_quality_output_acc: 0.5536 - age_output_acc: 0.4014 - weight_output_acc: 0.6376 - bag_output_acc: 0.6043 - footwear_output_acc: 0.6425 - pose_output_acc: 0.6226 - emotion_output_acc: 0.7169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "312/312 [==============================] - 158s 508ms/step - loss: 7.2859 - gender_output_loss: 0.5351 - image_quality_output_loss: 0.9700 - age_output_loss: 1.3905 - weight_output_loss: 0.9620 - bag_output_loss: 0.8626 - footwear_output_loss: 0.8112 - pose_output_loss: 0.8688 - emotion_output_loss: 0.8857 - gender_output_acc: 0.7266 - image_quality_output_acc: 0.5538 - age_output_acc: 0.4008 - weight_output_acc: 0.6374 - bag_output_acc: 0.6045 - footwear_output_acc: 0.6424 - pose_output_acc: 0.6225 - emotion_output_acc: 0.7167 - val_loss: 7.4884 - val_gender_output_loss: 0.5823 - val_image_quality_output_loss: 0.9701 - val_age_output_loss: 1.4198 - val_weight_output_loss: 0.9704 - val_bag_output_loss: 0.8926 - val_footwear_output_loss: 0.8331 - val_pose_output_loss: 0.8684 - val_emotion_output_loss: 0.9517 - val_gender_output_acc: 0.6880 - val_image_quality_output_acc: 0.5578 - val_age_output_acc: 0.3714 - val_weight_output_acc: 0.6401 - val_bag_output_acc: 0.5776 - val_footwear_output_acc: 0.6276 - val_pose_output_acc: 0.6141 - val_emotion_output_acc: 0.6870\n",
            "\n",
            "Epoch 00012: val_loss improved from 7.56320 to 7.48836, saving model to /content/drive/My Drive/Colab Notebooks/weights.12-7.49.hdf5\n",
            "Epoch 13/25\n",
            "312/312 [==============================] - 159s 509ms/step - loss: 7.2070 - gender_output_loss: 0.5248 - image_quality_output_loss: 0.9733 - age_output_loss: 1.3748 - weight_output_loss: 0.9582 - bag_output_loss: 0.8580 - footwear_output_loss: 0.7799 - pose_output_loss: 0.8617 - emotion_output_loss: 0.8763 - gender_output_acc: 0.7346 - image_quality_output_acc: 0.5484 - age_output_acc: 0.4128 - weight_output_acc: 0.6347 - bag_output_acc: 0.6032 - footwear_output_acc: 0.6607 - pose_output_acc: 0.6151 - emotion_output_acc: 0.7190 - val_loss: 7.4406 - val_gender_output_loss: 0.5491 - val_image_quality_output_loss: 0.9677 - val_age_output_loss: 1.4168 - val_weight_output_loss: 0.9759 - val_bag_output_loss: 0.8856 - val_footwear_output_loss: 0.8364 - val_pose_output_loss: 0.8640 - val_emotion_output_loss: 0.9451 - val_gender_output_acc: 0.7109 - val_image_quality_output_acc: 0.5604 - val_age_output_acc: 0.3677 - val_weight_output_acc: 0.6375 - val_bag_output_acc: 0.5781 - val_footwear_output_acc: 0.6276 - val_pose_output_acc: 0.6078 - val_emotion_output_acc: 0.6875\n",
            "\n",
            "Epoch 00013: val_loss improved from 7.48836 to 7.44056, saving model to /content/drive/My Drive/Colab Notebooks/weights.13-7.44.hdf5\n",
            "Epoch 14/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.2025 - gender_output_loss: 0.5191 - image_quality_output_loss: 0.9654 - age_output_loss: 1.3901 - weight_output_loss: 0.9680 - bag_output_loss: 0.8457 - footwear_output_loss: 0.7824 - pose_output_loss: 0.8449 - emotion_output_loss: 0.8871 - gender_output_acc: 0.7409 - image_quality_output_acc: 0.5580 - age_output_acc: 0.4040 - weight_output_acc: 0.6313 - bag_output_acc: 0.6198 - footwear_output_acc: 0.6611 - pose_output_acc: 0.6255 - emotion_output_acc: 0.7147\n",
            "Epoch 00013: val_loss improved from 7.48836 to 7.44056, saving model to /content/drive/My Drive/Colab Notebooks/weights.13-7.44.hdf5\n",
            "312/312 [==============================] - 159s 508ms/step - loss: 7.2026 - gender_output_loss: 0.5189 - image_quality_output_loss: 0.9655 - age_output_loss: 1.3904 - weight_output_loss: 0.9680 - bag_output_loss: 0.8462 - footwear_output_loss: 0.7822 - pose_output_loss: 0.8448 - emotion_output_loss: 0.8867 - gender_output_acc: 0.7408 - image_quality_output_acc: 0.5578 - age_output_acc: 0.4035 - weight_output_acc: 0.6316 - bag_output_acc: 0.6198 - footwear_output_acc: 0.6609 - pose_output_acc: 0.6255 - emotion_output_acc: 0.7148 - val_loss: 7.6145 - val_gender_output_loss: 0.5580 - val_image_quality_output_loss: 0.9804 - val_age_output_loss: 1.4211 - val_weight_output_loss: 0.9651 - val_bag_output_loss: 0.9000 - val_footwear_output_loss: 0.9878 - val_pose_output_loss: 0.8534 - val_emotion_output_loss: 0.9487 - val_gender_output_acc: 0.7063 - val_image_quality_output_acc: 0.5490 - val_age_output_acc: 0.3688 - val_weight_output_acc: 0.6438 - val_bag_output_acc: 0.5792 - val_footwear_output_acc: 0.5615 - val_pose_output_acc: 0.6276 - val_emotion_output_acc: 0.6854\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 7.44056\n",
            "Epoch 15/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.2264 - gender_output_loss: 0.5223 - image_quality_output_loss: 0.9699 - age_output_loss: 1.3807 - weight_output_loss: 0.9588 - bag_output_loss: 0.8649 - footwear_output_loss: 0.7912 - pose_output_loss: 0.8533 - emotion_output_loss: 0.8854 - gender_output_acc: 0.7364 - image_quality_output_acc: 0.5547 - age_output_acc: 0.4066 - weight_output_acc: 0.6362 - bag_output_acc: 0.6028 - footwear_output_acc: 0.6529 - pose_output_acc: 0.6283 - emotion_output_acc: 0.7155\n",
            "Epoch 00014: val_loss did not improve from 7.44056\n",
            "Epoch 15/25\n",
            "312/312 [==============================] - 159s 510ms/step - loss: 7.2250 - gender_output_loss: 0.5220 - image_quality_output_loss: 0.9700 - age_output_loss: 1.3810 - weight_output_loss: 0.9582 - bag_output_loss: 0.8647 - footwear_output_loss: 0.7911 - pose_output_loss: 0.8532 - emotion_output_loss: 0.8849 - gender_output_acc: 0.7369 - image_quality_output_acc: 0.5547 - age_output_acc: 0.4064 - weight_output_acc: 0.6366 - bag_output_acc: 0.6030 - footwear_output_acc: 0.6530 - pose_output_acc: 0.6287 - emotion_output_acc: 0.7157 - val_loss: 7.7084 - val_gender_output_loss: 0.5596 - val_image_quality_output_loss: 0.9777 - val_age_output_loss: 1.4125 - val_weight_output_loss: 0.9709 - val_bag_output_loss: 0.8903 - val_footwear_output_loss: 1.0941 - val_pose_output_loss: 0.8568 - val_emotion_output_loss: 0.9464 - val_gender_output_acc: 0.7052 - val_image_quality_output_acc: 0.5578 - val_age_output_acc: 0.3667 - val_weight_output_acc: 0.6417 - val_bag_output_acc: 0.5786 - val_footwear_output_acc: 0.5125 - val_pose_output_acc: 0.6391 - val_emotion_output_acc: 0.6854\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 7.44056\n",
            "Epoch 16/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.2174 - gender_output_loss: 0.5301 - image_quality_output_loss: 0.9695 - age_output_loss: 1.3857 - weight_output_loss: 0.9635 - bag_output_loss: 0.8588 - footwear_output_loss: 0.7928 - pose_output_loss: 0.8358 - emotion_output_loss: 0.8812 - gender_output_acc: 0.7330 - image_quality_output_acc: 0.5560 - age_output_acc: 0.4079 - weight_output_acc: 0.6358 - bag_output_acc: 0.6093 - footwear_output_acc: 0.6516 - pose_output_acc: 0.6365 - emotion_output_acc: 0.7169\n",
            "Epoch 00015: val_loss did not improve from 7.44056\n",
            "Epoch 16/25\n",
            "312/312 [==============================] - 158s 507ms/step - loss: 7.2185 - gender_output_loss: 0.5302 - image_quality_output_loss: 0.9699 - age_output_loss: 1.3857 - weight_output_loss: 0.9634 - bag_output_loss: 0.8586 - footwear_output_loss: 0.7932 - pose_output_loss: 0.8359 - emotion_output_loss: 0.8816 - gender_output_acc: 0.7330 - image_quality_output_acc: 0.5558 - age_output_acc: 0.4080 - weight_output_acc: 0.6358 - bag_output_acc: 0.6093 - footwear_output_acc: 0.6513 - pose_output_acc: 0.6360 - emotion_output_acc: 0.7168 - val_loss: 7.4096 - val_gender_output_loss: 0.5519 - val_image_quality_output_loss: 0.9699 - val_age_output_loss: 1.4092 - val_weight_output_loss: 0.9702 - val_bag_output_loss: 0.9046 - val_footwear_output_loss: 0.8330 - val_pose_output_loss: 0.8327 - val_emotion_output_loss: 0.9381 - val_gender_output_acc: 0.7219 - val_image_quality_output_acc: 0.5578 - val_age_output_acc: 0.3703 - val_weight_output_acc: 0.6375 - val_bag_output_acc: 0.5740 - val_footwear_output_acc: 0.6276 - val_pose_output_acc: 0.6443 - val_emotion_output_acc: 0.6906\n",
            "\n",
            "Epoch 00016: val_loss improved from 7.44056 to 7.40959, saving model to /content/drive/My Drive/Colab Notebooks/weights.16-7.41.hdf5\n",
            "Epoch 17/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.2440 - gender_output_loss: 0.5344 - image_quality_output_loss: 0.9782 - age_output_loss: 1.3834 - weight_output_loss: 0.9585 - bag_output_loss: 0.8698 - footwear_output_loss: 0.8072 - pose_output_loss: 0.8249 - emotion_output_loss: 0.8876 - gender_output_acc: 0.7308 - image_quality_output_acc: 0.5485 - age_output_acc: 0.4123 - weight_output_acc: 0.6389 - bag_output_acc: 0.5991 - footwear_output_acc: 0.6447 - pose_output_acc: 0.6493 - emotion_output_acc: 0.7145\n",
            "Epoch 00016: val_loss improved from 7.44056 to 7.40959, saving model to /content/drive/My Drive/Colab Notebooks/weights.16-7.41.hdf5\n",
            "312/312 [==============================] - 158s 508ms/step - loss: 7.2426 - gender_output_loss: 0.5344 - image_quality_output_loss: 0.9782 - age_output_loss: 1.3825 - weight_output_loss: 0.9586 - bag_output_loss: 0.8697 - footwear_output_loss: 0.8072 - pose_output_loss: 0.8246 - emotion_output_loss: 0.8875 - gender_output_acc: 0.7309 - image_quality_output_acc: 0.5486 - age_output_acc: 0.4132 - weight_output_acc: 0.6388 - bag_output_acc: 0.5990 - footwear_output_acc: 0.6446 - pose_output_acc: 0.6494 - emotion_output_acc: 0.7145 - val_loss: 7.4550 - val_gender_output_loss: 0.5716 - val_image_quality_output_loss: 0.9734 - val_age_output_loss: 1.4262 - val_weight_output_loss: 0.9685 - val_bag_output_loss: 0.9027 - val_footwear_output_loss: 0.8150 - val_pose_output_loss: 0.8390 - val_emotion_output_loss: 0.9585 - val_gender_output_acc: 0.6964 - val_image_quality_output_acc: 0.5563 - val_age_output_acc: 0.3755 - val_weight_output_acc: 0.6484 - val_bag_output_acc: 0.5667 - val_footwear_output_acc: 0.6375 - val_pose_output_acc: 0.6500 - val_emotion_output_acc: 0.6870\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 7.40959\n",
            "Epoch 18/25\n",
            "312/312 [==============================] - 158s 508ms/step - loss: 7.2181 - gender_output_loss: 0.5255 - image_quality_output_loss: 0.9679 - age_output_loss: 1.3961 - weight_output_loss: 0.9725 - bag_output_loss: 0.8641 - footwear_output_loss: 0.8023 - pose_output_loss: 0.8058 - emotion_output_loss: 0.8839 - gender_output_acc: 0.7353 - image_quality_output_acc: 0.5560 - age_output_acc: 0.4001 - weight_output_acc: 0.6325 - bag_output_acc: 0.5970 - footwear_output_acc: 0.6504 - pose_output_acc: 0.6529 - emotion_output_acc: 0.7157 - val_loss: 7.6323 - val_gender_output_loss: 0.5962 - val_image_quality_output_loss: 0.9749 - val_age_output_loss: 1.4287 - val_weight_output_loss: 0.9770 - val_bag_output_loss: 0.9064 - val_footwear_output_loss: 0.8814 - val_pose_output_loss: 0.9061 - val_emotion_output_loss: 0.9616 - val_gender_output_acc: 0.6875 - val_image_quality_output_acc: 0.5531 - val_age_output_acc: 0.3688 - val_weight_output_acc: 0.6401 - val_bag_output_acc: 0.5573 - val_footwear_output_acc: 0.6010 - val_pose_output_acc: 0.5839 - val_emotion_output_acc: 0.6859\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 7.40959\n",
            "Epoch 19/25\n",
            "312/312 [==============================] - 159s 510ms/step - loss: 7.2043 - gender_output_loss: 0.5348 - image_quality_output_loss: 0.9752 - age_output_loss: 1.3909 - weight_output_loss: 0.9704 - bag_output_loss: 0.8714 - footwear_output_loss: 0.8095 - pose_output_loss: 0.7783 - emotion_output_loss: 0.8737 - gender_output_acc: 0.7269 - image_quality_output_acc: 0.5501 - age_output_acc: 0.4085 - weight_output_acc: 0.6327 - bag_output_acc: 0.6023 - footwear_output_acc: 0.6446 - pose_output_acc: 0.6720 - emotion_output_acc: 0.7219 - val_loss: 7.7675 - val_gender_output_loss: 0.6032 - val_image_quality_output_loss: 0.9832 - val_age_output_loss: 1.4277 - val_weight_output_loss: 0.9869 - val_bag_output_loss: 0.9127 - val_footwear_output_loss: 0.8674 - val_pose_output_loss: 0.9844 - val_emotion_output_loss: 1.0020 - val_gender_output_acc: 0.6818 - val_image_quality_output_acc: 0.5505 - val_age_output_acc: 0.3682 - val_weight_output_acc: 0.6427 - val_bag_output_acc: 0.5719 - val_footwear_output_acc: 0.6099 - val_pose_output_acc: 0.5193 - val_emotion_output_acc: 0.6859\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 7.40959\n",
            "Epoch 20/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 7.1374 - gender_output_loss: 0.5214 - image_quality_output_loss: 0.9650 - age_output_loss: 1.3901 - weight_output_loss: 0.9677 - bag_output_loss: 0.8626 - footwear_output_loss: 0.8036 - pose_output_loss: 0.7419 - emotion_output_loss: 0.8851 - gender_output_acc: 0.7380 - image_quality_output_acc: 0.5627 - age_output_acc: 0.4045 - weight_output_acc: 0.6307 - bag_output_acc: 0.6029 - footwear_output_acc: 0.6456 - pose_output_acc: 0.6828 - emotion_output_acc: 0.7121\n",
            "Epoch 00019: val_loss did not improve from 7.40959\n",
            "Epoch 20/25\n",
            "312/312 [==============================] - 159s 509ms/step - loss: 7.1352 - gender_output_loss: 0.5209 - image_quality_output_loss: 0.9653 - age_output_loss: 1.3899 - weight_output_loss: 0.9677 - bag_output_loss: 0.8622 - footwear_output_loss: 0.8032 - pose_output_loss: 0.7413 - emotion_output_loss: 0.8847 - gender_output_acc: 0.7386 - image_quality_output_acc: 0.5627 - age_output_acc: 0.4042 - weight_output_acc: 0.6308 - bag_output_acc: 0.6035 - footwear_output_acc: 0.6459 - pose_output_acc: 0.6832 - emotion_output_acc: 0.7123 - val_loss: 8.4888 - val_gender_output_loss: 0.8186 - val_image_quality_output_loss: 0.9829 - val_age_output_loss: 1.4605 - val_weight_output_loss: 1.0059 - val_bag_output_loss: 1.0485 - val_footwear_output_loss: 1.3143 - val_pose_output_loss: 0.8694 - val_emotion_output_loss: 0.9887 - val_gender_output_acc: 0.6349 - val_image_quality_output_acc: 0.5542 - val_age_output_acc: 0.3641 - val_weight_output_acc: 0.6182 - val_bag_output_acc: 0.5469 - val_footwear_output_acc: 0.5146 - val_pose_output_acc: 0.6208 - val_emotion_output_acc: 0.6802\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 7.40959\n",
            "Epoch 21/25\n",
            "312/312 [==============================] - 159s 509ms/step - loss: 7.0405 - gender_output_loss: 0.4987 - image_quality_output_loss: 0.9754 - age_output_loss: 1.3814 - weight_output_loss: 0.9581 - bag_output_loss: 0.8560 - footwear_output_loss: 0.7892 - pose_output_loss: 0.7013 - emotion_output_loss: 0.8803 - gender_output_acc: 0.7606 - image_quality_output_acc: 0.5463 - age_output_acc: 0.4088 - weight_output_acc: 0.6363 - bag_output_acc: 0.6069 - footwear_output_acc: 0.6579 - pose_output_acc: 0.7059 - emotion_output_acc: 0.7122 - val_loss: 7.6742 - val_gender_output_loss: 0.5531 - val_image_quality_output_loss: 0.9820 - val_age_output_loss: 1.4118 - val_weight_output_loss: 0.9627 - val_bag_output_loss: 0.9046 - val_footwear_output_loss: 1.1716 - val_pose_output_loss: 0.7520 - val_emotion_output_loss: 0.9366 - val_gender_output_acc: 0.7156 - val_image_quality_output_acc: 0.5505 - val_age_output_acc: 0.3854 - val_weight_output_acc: 0.6469 - val_bag_output_acc: 0.5729 - val_footwear_output_acc: 0.4646 - val_pose_output_acc: 0.6745 - val_emotion_output_acc: 0.6865\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 7.40959\n",
            "Epoch 22/25\n",
            "312/312 [==============================] - 159s 509ms/step - loss: 6.8771 - gender_output_loss: 0.4583 - image_quality_output_loss: 0.9715 - age_output_loss: 1.3704 - weight_output_loss: 0.9539 - bag_output_loss: 0.8467 - footwear_output_loss: 0.7750 - pose_output_loss: 0.6359 - emotion_output_loss: 0.8654 - gender_output_acc: 0.7825 - image_quality_output_acc: 0.5507 - age_output_acc: 0.4079 - weight_output_acc: 0.6343 - bag_output_acc: 0.6172 - footwear_output_acc: 0.6679 - pose_output_acc: 0.7330 - emotion_output_acc: 0.7188 - val_loss: 7.2026 - val_gender_output_loss: 0.5064 - val_image_quality_output_loss: 0.9685 - val_age_output_loss: 1.4050 - val_weight_output_loss: 0.9497 - val_bag_output_loss: 0.8977 - val_footwear_output_loss: 0.8378 - val_pose_output_loss: 0.7090 - val_emotion_output_loss: 0.9285 - val_gender_output_acc: 0.7568 - val_image_quality_output_acc: 0.5536 - val_age_output_acc: 0.3703 - val_weight_output_acc: 0.6427 - val_bag_output_acc: 0.5875 - val_footwear_output_acc: 0.6078 - val_pose_output_acc: 0.7073 - val_emotion_output_acc: 0.6859\n",
            "\n",
            "Epoch 00022: val_loss improved from 7.40959 to 7.20257, saving model to /content/drive/My Drive/Colab Notebooks/weights.22-7.20.hdf5\n",
            "Epoch 23/25\n",
            "311/312 [============================>.] - ETA: 0s - loss: 6.7376 - gender_output_loss: 0.4243 - image_quality_output_loss: 0.9632 - age_output_loss: 1.3572 - weight_output_loss: 0.9469 - bag_output_loss: 0.8379 - footwear_output_loss: 0.7532 - pose_output_loss: 0.5925 - emotion_output_loss: 0.8625 - gender_output_acc: 0.8043 - image_quality_output_acc: 0.5591 - age_output_acc: 0.4107 - weight_output_acc: 0.6340 - bag_output_acc: 0.6304 - footwear_output_acc: 0.6729 - pose_output_acc: 0.7580 - emotion_output_acc: 0.7159\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "312/312 [==============================] - 158s 506ms/step - loss: 6.7370 - gender_output_loss: 0.4243 - image_quality_output_loss: 0.9633 - age_output_loss: 1.3573 - weight_output_loss: 0.9464 - bag_output_loss: 0.8380 - footwear_output_loss: 0.7529 - pose_output_loss: 0.5922 - emotion_output_loss: 0.8625 - gender_output_acc: 0.8043 - image_quality_output_acc: 0.5589 - age_output_acc: 0.4102 - weight_output_acc: 0.6345 - bag_output_acc: 0.6305 - footwear_output_acc: 0.6733 - pose_output_acc: 0.7583 - emotion_output_acc: 0.7159 - val_loss: 7.1648 - val_gender_output_loss: 0.5447 - val_image_quality_output_loss: 0.9669 - val_age_output_loss: 1.4133 - val_weight_output_loss: 0.9434 - val_bag_output_loss: 0.8864 - val_footwear_output_loss: 0.8158 - val_pose_output_loss: 0.6709 - val_emotion_output_loss: 0.9235 - val_gender_output_acc: 0.7349 - val_image_quality_output_acc: 0.5578 - val_age_output_acc: 0.3792 - val_weight_output_acc: 0.6474 - val_bag_output_acc: 0.5776 - val_footwear_output_acc: 0.6339 - val_pose_output_acc: 0.7250 - val_emotion_output_acc: 0.6865\n",
            "\n",
            "Epoch 00023: val_loss improved from 7.20257 to 7.16478, saving model to /content/drive/My Drive/Colab Notebooks/weights.23-7.16.hdf5\n",
            "Epoch 24/25\n",
            "312/312 [==============================] - 159s 509ms/step - loss: 6.6003 - gender_output_loss: 0.3796 - image_quality_output_loss: 0.9662 - age_output_loss: 1.3550 - weight_output_loss: 0.9374 - bag_output_loss: 0.8256 - footwear_output_loss: 0.7375 - pose_output_loss: 0.5430 - emotion_output_loss: 0.8561 - gender_output_acc: 0.8291 - image_quality_output_acc: 0.5531 - age_output_acc: 0.4125 - weight_output_acc: 0.6339 - bag_output_acc: 0.6366 - footwear_output_acc: 0.6857 - pose_output_acc: 0.7775 - emotion_output_acc: 0.7157 - val_loss: 8.7415 - val_gender_output_loss: 0.7896 - val_image_quality_output_loss: 0.9844 - val_age_output_loss: 1.4296 - val_weight_output_loss: 0.9710 - val_bag_output_loss: 0.9039 - val_footwear_output_loss: 1.9501 - val_pose_output_loss: 0.7639 - val_emotion_output_loss: 0.9489 - val_gender_output_acc: 0.5938 - val_image_quality_output_acc: 0.5474 - val_age_output_acc: 0.3708 - val_weight_output_acc: 0.6438 - val_bag_output_acc: 0.5776 - val_footwear_output_acc: 0.3745 - val_pose_output_acc: 0.6583 - val_emotion_output_acc: 0.6833\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 7.16478\n",
            "Epoch 25/25\n",
            "312/312 [==============================] - 159s 509ms/step - loss: 6.4576 - gender_output_loss: 0.3426 - image_quality_output_loss: 0.9540 - age_output_loss: 1.3504 - weight_output_loss: 0.9327 - bag_output_loss: 0.8124 - footwear_output_loss: 0.7302 - pose_output_loss: 0.4908 - emotion_output_loss: 0.8445 - gender_output_acc: 0.8482 - image_quality_output_acc: 0.5619 - age_output_acc: 0.4127 - weight_output_acc: 0.6335 - bag_output_acc: 0.6437 - footwear_output_acc: 0.6909 - pose_output_acc: 0.8029 - emotion_output_acc: 0.7184 - val_loss: 7.0398 - val_gender_output_loss: 0.4836 - val_image_quality_output_loss: 0.9615 - val_age_output_loss: 1.4043 - val_weight_output_loss: 0.9513 - val_bag_output_loss: 0.8777 - val_footwear_output_loss: 0.8012 - val_pose_output_loss: 0.6379 - val_emotion_output_loss: 0.9221 - val_gender_output_acc: 0.7828 - val_image_quality_output_acc: 0.5599 - val_age_output_acc: 0.3797 - val_weight_output_acc: 0.6391 - val_bag_output_acc: 0.5969 - val_footwear_output_acc: 0.6453 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.6849\n",
            "\n",
            "Epoch 00025: val_loss improved from 7.16478 to 7.03976, saving model to /content/drive/My Drive/Colab Notebooks/weights.25-7.04.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}